{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('v0.2_orig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.],\n",
       "       [   0.],\n",
       "       [   0.],\n",
       "       ...,\n",
       "       [9900.],\n",
       "       [9900.],\n",
       "       [9900.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = training_set.iloc[:,1:2].values\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        _x = data[i:(i+seq_length)]\n",
    "        _y = data[i+seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "training_data = sc.fit_transform(training_set)\n",
    "\n",
    "seq_length = 4\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "\n",
    "train_size = int(len(y) * 0.67)\n",
    "test_size = len(y) - train_size\n",
    "\n",
    "dataX = Variable(torch.Tensor(np.array(x)))\n",
    "dataY = Variable(torch.Tensor(np.array(y)))\n",
    "\n",
    "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
    "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
    "\n",
    "testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n",
    "testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        \n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.22763\n",
      "Epoch: 100, loss: 0.03191\n",
      "Epoch: 200, loss: 0.01825\n",
      "Epoch: 300, loss: 0.00344\n",
      "Epoch: 400, loss: 0.00021\n",
      "Epoch: 500, loss: 0.00008\n",
      "Epoch: 600, loss: 0.00008\n",
      "Epoch: 700, loss: 0.00008\n",
      "Epoch: 800, loss: 0.00008\n",
      "Epoch: 900, loss: 0.00007\n",
      "Epoch: 1000, loss: 0.00007\n",
      "Epoch: 1100, loss: 0.00007\n",
      "Epoch: 1200, loss: 0.00007\n",
      "Epoch: 1300, loss: 0.00007\n",
      "Epoch: 1400, loss: 0.00007\n",
      "Epoch: 1500, loss: 0.00007\n",
      "Epoch: 1600, loss: 0.00007\n",
      "Epoch: 1700, loss: 0.00006\n",
      "Epoch: 1800, loss: 0.00006\n",
      "Epoch: 1900, loss: 0.00006\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
    "\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm(trainX)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, trainY)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm.eval()\n",
    "train_predict = lstm(dataX)\n",
    "\n",
    "data_predict = train_predict.data.numpy()\n",
    "dataY_plot = dataY.data.numpy()\n",
    "\n",
    "data_predict = sc.inverse_transform(data_predict)\n",
    "dataY_plot = sc.inverse_transform(dataY_plot)\n",
    "\n",
    "plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "\n",
    "plt.plot(dataY_plot)\n",
    "plt.plot(data_predict)\n",
    "plt.suptitle('Time-Series Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('v0.2_orig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros([len(data.index),1]) #Features: Time, Difference, Rate\n",
    "y = np.zeros([len(data.index),1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,0] = data.x.values\n",
    "#X[:,1] = data.y.values\n",
    "y = data.Phi.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_features=1\n",
    "train= len(data.index)-20\n",
    "test = len(data.index) - train\n",
    "X_train = X[:train,:]\n",
    "X_test= X[train:,:]\n",
    "y_train = y[:train] \n",
    "y_test = y[train:]\n",
    "\n",
    "y_train = y_train.reshape((y_train.shape[0]),1)\n",
    "y_test = y_test.reshape((y_test.shape[0]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensors_final = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "X_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape torch.Size([9980, 1, 1]) torch.Size([9980, 1])\n",
      "Testing Shape torch.Size([20, 1, 1]) torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Shape\", X_train_tensors_final.shape, y_train_tensors.shape)\n",
    "print(\"Testing Shape\", X_test_tensors_final.shape, y_test_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length, p = 0.01):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 1024) #fully connected 1\n",
    "        self.fc_2 =  nn.Linear(1024,1024) #fully connected 1\n",
    "        self.fc_3 =  nn.Linear(64,32) #fully connected 1\n",
    "        self.fc = nn.Linear(1024, num_classes) #fully connected last layer\n",
    "        self.p = p\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        out = self.relu(hn)\n",
    "        #out = nn.functional.dropout(out, p=self.p, training=True)\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = nn.functional.dropout(out, p=self.p, training=True)\n",
    "        out = self.relu(out) #relu\n",
    "        \n",
    "        out = self.fc_2(out) #second Dense\n",
    "        out = nn.functional.dropout(out, p=self.p, training=True)\n",
    "        out = self.relu(out) #relu\n",
    "                \n",
    "        out = self.fc(out) #Final Output\n",
    "        return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 700 #1000 epochs\n",
    "learning_rate = 0.001#0.001 #0.001 lr\n",
    "\n",
    "input_size = 3 #number of features\n",
    "hidden_size = 7*96#6 #number of features in hidden state #10, 9\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "num_classes = 1 #number of output classes \n",
    "\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = LSTM1(num_classes,\n",
    "              input_size,\n",
    "              hidden_size,\n",
    "              num_layers,\n",
    "              trainX.shape[1],\n",
    "              p=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 3, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-9a2545d6c70a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss_test_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tensors_final\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#caluclate the gradient, manually setting to 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-fe8b882e91a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mc_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#internal state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Propagate input through LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#lstm with input, hidden, and internal state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#reshaping the data for Dense layer next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    682\u001b[0m                            \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                            ):\n\u001b[0;32m--> 684\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[1;32m    686\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    203\u001b[0m                     expected_input_dim, input.dim()))\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    206\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[1;32m    207\u001b[0m                     self.input_size, input.size(-1)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 3, got 1"
     ]
    }
   ],
   "source": [
    "loss_values=[]\n",
    "loss_test_values=[]\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm1.forward(X_train_tensors_final) #forward pass\n",
    "    optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    "\n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, y_train_tensors)\n",
    "    loss.backward() #calculates the loss of the loss function\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    \n",
    "    test_output = lstm1.forward(X_test_tensors_final) #forward pass\n",
    "    loss_test = criterion(test_output, y_test_tensors)\n",
    "    #scheduler.step(loss_test)\n",
    "    loss_test_values.append(loss_test.item())\n",
    "\n",
    "    optimizer.step() #improve from loss, i.e backprop\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
    "        print(f'Epoch: {epoch:3.0f}, MAE: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
